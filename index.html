<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <style type="text/css">
    /* Color scheme from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    ul {
    list-style-position:outside;
    }
  </style>

  <title>Tao Ma</title>

  <meta name="author" content="Tao Ma">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tao Ma &nbsp;</name><img src="./images/name.jpg" align="top" height="35" width="75">
              </p>
              <p>
                I am currently a 3rd-year Ph.D. candidate at <a href="https://mmlab.ie.cuhk.edu.hk/people.html" target="_blank"> Multimedia Laboratory</a> (MMLab) of The Chinese University of Hong Kong, supervised by Prof. <a href="https://www.ee.cuhk.edu.hk/~hsli/" target="_blank">Hongsheng Li</a> and Prof. <a href="https://www.ee.cuhk.edu.hk/~xgwang/" target="_blank">Xiaogang Wang</a>. My research focuses on scene perception and understanding in autonomous driving, which mainly includes onboard and offboard 3D object detection with point cloud and image data.
              </p>
              <p>
                Better research, better life. I love cycling sports, please feel free to contact me if you have any questions or similar interests.
              </p>
              <p style="text-align:center;">SHB 310, CUHK, Hong Kong SAR, China</p>
              <p style="text-align:center;margin-top:-10px;">
                <a href="mailto:taoma_nwpu@hotmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=9h86v8kAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/superkoma" target="_blank"> Github </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/tao-ma-449091163" target="_blank"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:45%;max-width:45%;padding-top:10%">
              <a href="images/matao.jpg"><img style="width:75%;max-width:75%" alt="profile photo" src="images/matao.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>News</heading>
                </p>
                <p>
                  <LI> [2024.12] One paper is accepted by AAAI 2025.</LI>
                  <LI> [2024.09] üöÄ One paper is accepted by NeurIPS 2024.</LI>
                  <LI> [2024.09] One paper is submitted to T-PAMI (under review).</LI>
                  <LI> [2024.01] VeloVox is accepted by ICRA 2024.</LI>
                  <LI> [2024.01] DiLu is accepted by ICLR 2024.</LI>
                  <LI> [2023.07] DetZero is accepted by ICCV 2023.</LI>
                  <LI> [2023.03] üèÜ DetZero ranks <b>1st</b> place with 85.15 mAPH (L2) on <a href="https://waymo.com/open/challenges/2020/3d-detection" target="_blank">Waymo 3D detection leadboard</a>.
                  <LI> [2022.08] Back to school from industry and start my Ph.D. career at MMLab of CUHK.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;padding-top:5px;vertical-align:middle">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>Education</heading>
                </p>
                <p>
                  <LI> [2022 - Now]&nbsp; Ph.D., Electronic Engineering, <a href="https://www.cuhk.edu.hk/english/index.html" target="_blank">The Chinese University of Hong Kong</a> </LI>
                  <LI> [2017 - 2020]&nbsp; M. Eng., Pattern Recognition and Intelligent System, <a href="https://en.nwpu.edu.cn/" target="_blank">Northwestern Polytechnical University</a> </LI>
                  <LI> [2013 - 2017]&nbsp; B. Eng., Information Engineering, <a href="https://en.nwpu.edu.cn/" target="_blank">Northwestern Polytechnical University</a> </LI>
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;padding-top:5px;vertical-align:middle">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>Working Experience</heading>
                </p>
                <p>
                  <LI> [2021.05 - 2022.08]&nbsp; Researcher, <a href="https://pjlab-adg.github.io/" target="_blank">Autonomous Driving Lab</a>, Shanghai AI Laboratory </LI>
                  <LI> [2020.04 - 2021.05]&nbsp; Researcher, Autonomous Driving Group, <a href="https://www.sensetime.com" target="_blank">SenseTime</a> </LI>
                  <LI> [2019.04 - 2020.04]&nbsp; Intern Researcher, Autonomous Driving Group, <a href="https://www.sensetime.com" target="_blank">SenseTime</a> </LI>
                  <LI> [2018.10 - 2019.04]&nbsp; Research Intern, <a href="https://www.microsoft.com/en-us/research/group/media-computing-group" target="_blank">Media Computing Group</a>, Microsoft Research Asia </LI>
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding-left:20px;width:100%;vertical-align:middle">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>Publications</heading>
                </p>
                <p>
                  * indicates equal contribution to the work.
                </p>
              </td>
            </tr>
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <tr>
            <td style="width:100%;padding-left:10px;padding-top:0px;vertical-align:middle">
              <ul style="list-style-type:square;">

                <LI style="padding-bottom:15px;">
                  <a href="" target="_blank">
                  <papertitle>ZOPP: A Framework of Zero-shot Offboard Panoptic Perception for Autonomous Driving</papertitle>
                  </a>
                  <br><strong>T. Ma*</strong>, H. Zhou*, Q. Huang*, X. Yang, J. Guo, B. Zhang, M. Dou, Y. Qiao, B. Shi, H. Li
                  <br>
                  <em>Conference on Neural Information Processing Systems (<b>NeurIPS</b>)</em>, 2024
                  <br>
                  [<a href="https://arxiv.org/abs/2411.05311" target="_blank">arXiv</a> / <a href="https://github.com/PJLab-ADG/ZOPP" target="_blank">Code</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="" target="_blank">
                  <papertitle>VeloVox: A Low-cost and Accurate 4D Object Detector with Single-frame Point Cloud of Livox LiDAR</papertitle>
                  </a>
                  <br><strong>T. Ma*</strong>, Z. Zheng*, H. Zhou, X. Cai, X. Yang, Y. Li, B. Shi, H. Li
                  <br>
                  <em>IEEE International Conference on Robotics and Automation (<b>ICRA</b>)</em>, 2024
                  <br>
                  [<a href="" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2309.16292.pdf" target="_blank">
                  <papertitle>DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models</papertitle>
                  </a>
                  <br> L. Wen*, D. Fu*, X. Li*, X. Cai, <strong>T. Ma</strong>, P. Cai, M. Dou, B. Shi, L. He, Y. Qiao
                  <br>
                  <em>International Conference on Learning Representations (<b>ICLR</b>)</em>, 2024
                  <br>
                  [<a href="https://arxiv.org/abs/2309.16292" target="_blank">arXiv</a> / <a href="https://github.com/PJLab-ADG/DiLu" target="_blank">Code</a> / <a href="https://pjlab-adg.github.io/DiLu/" target="_blank">Project Page</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/abs/2306.06023.pdf" target="_blank">
                  <papertitle>DetZero: Rethinking Offboard 3D Object Detection with Long-term Sequential Point Clouds</papertitle>
                  </a>
                  <br><strong>T. Ma</strong>, X. Yang, H. Zhou, X. Li, B. Shi, J. Liu, Y. Yang, Z. Liu, L. He, Y. Qiao, Y. Li, H. Li
                  <br>
                  <em>International Conference on Computer Vision (<b>ICCV</b>)</em>, 2023
                  <br>
                  [<a href="https://arxiv.org/abs/2306.06023" target="_blank">arXiv</a> /
                  <a href="https://github.com/PJLab-ADG/DetZero" target="_blank">Code</a> / <a href="https://superkoma.github.io/detzero-page/" target="_blank">Project Page</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="" target="_blank">
                  <papertitle>RangePerception: Taming LiDAR Range View for Efficient and Accurate 3D Object Detection</papertitle>
                  </a>
                  <br> Y. Bai, B. Fei, Y. Liu, <strong>T. Ma</strong>, Y. Hou, B. Shi, Y. Li
                  <br>
                  <em>Conference on Neural Information Processing Systems (<b>NeurIPS</b>)</em>, 2023
                  <br>
                  [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/fb8e52adcd9b59bad73f109c53afc43a-Paper-Conference.pdf" target="_blank">Paper</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2303.03595.pdf" target="_blank">
                  <papertitle>LogoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion</papertitle>
                  </a>
                  <br> X. Li, <strong>T. Ma</strong>, Y. Hou, B. Shi, Y. Yang, Y. Liu, X. Wu, Q. Chen, Y. Li, Y. Qiao, L. He
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</em>, 2022
                  <br>
                  [<a href="https://arxiv.org/abs/2303.03595" target="_blank">arXiv</a> / <a href="https://github.com/PJLab-ADG/LogoNet" target="_blank">Code</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2006.05888.pdf" target="_blank">
                  <papertitle>Speech Fusion to Face: Bridging the Gap Between Human's Vocal Characteristics and Facial Imaging</papertitle>
                  </a>
                  <br> Y. Bai, <strong>T. Ma</strong>, L. Wang, Z. Zhang
                  <br>
                  <em>ACM International Conference on Multimedia (<b>ACM MM</b>)</em>, 2022
                  <br>
                  [<a href="https://arxiv.org/abs/2006.05888" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/1905.01608.pdf" target="_blank">
                  <papertitle>PasteGAN: A Semi-Parametric Method to Generate Image from Scene Graph</papertitle>
                  </a>
                  <br> Y. Li*, <strong>T. Ma*</strong>, Y. Bai, N. Duan, S. Wei, X. Wang
                  <br>
                  <em>Conference on Neural Information Processing Systems (<b>NeurIPS</b>)</em>, 2019
                  <br>
                  [<a href="https://arxiv.org/abs/1905.01608" target="_blank">arXiv</a> /
                  <a href="https://github.com/superkoma" target="_blank">code</a>]
                </LI>
              </ul>
            </td>
          </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding-left:20px;width:100%;vertical-align:middle">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>Preprints</heading>
                </p>
                <p>
                  * indicates equal contribution to the work.
                </p>
              </td>
            </tr>
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <tr>
            <td style="width:100%;padding-left:10px;padding-top:0px;vertical-align:middle">
              <ul style="list-style-type:square;">
                <LI style="padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2312.04316.pdf" target="_blank">
                  <papertitle>Towards Knowledge-driven Autonomous Driving</papertitle>
                  </a>
                  <br> X. Li, Y. Bai, P. Cai, L. Wen, D. Fu, B. Zhang, X. Yang, X. Cai, <strong>T. Ma</strong>, J. Guo, X. Gao, M. Dou, Y. Li, B. Shi, Y. Liu, L. He, Y. Qiao
                  <br>
                  <em>arXiv preprint</em>, 2023
                  <br>
                  [<a href="https://arxiv.org/abs/2312.04316" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2311.05332.pdf" target="_blank">
                  <papertitle>On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving</papertitle>
                  </a>
                  <br> L. Wen, X. Yang, D. Fu, X. Wang, P. Cai, X. Li, <strong>T. Ma</strong>, Y. Li, L. Xu, D. Shang, Z. Zhu, S. Sun, Y. Bai, X. Cai, M. Dou, S. Hu, B. Shi, Y. Qiao
                  <br>
                  <em>arXiv preprint</em>, 2023
                  <br>
                  [<a href="https://arxiv.org/abs/2311.05332" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2205.14087.pdf" target="_blank">
                  <papertitle>Opencalib: A multi-sensor calibration toolbox for autonomous driving</papertitle>
                  </a>
                  <br> G. Yan, Z. Liu, C. Wang, C. Shi, P. Wei, X. Cai, <strong>T. Ma</strong>, Z. Liu, Z. Zhong, Y. Liu, M. Zhao, Z. Ma, Y. Li
                  <br>
                  <em>arXiv preprint</em>, 2022
                  <br>
                  [<a href="https://arxiv.org/abs/2205.14087" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2103.04558.pdf" target="_blank">
                  <papertitle>CRLF: Automatic Calibration and Refinement based on Line Feature for LiDAR and Camera in Road Scenes</papertitle>
                  </a>
                  <br> <strong>T. Ma*</strong>, Z. Liu*, G. Yan, Y. Li
                  <br>
                  <em>arXiv preprint</em>, 2020
                  <br>
                  [<a href="https://arxiv.org/abs/2103.04558" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2104.06615.pdf" target="_blank">
                  <papertitle>Perception Entropy: A Metric for Multiple Sensors Configuration Evaluation and Design</papertitle>
                  </a>
                  <br> <strong>T. Ma*</strong>, Z. Liu*, Y. Li
                  <br>
                  <em>arXiv preprint</em>, 2020
                  <br>
                  [<a href="https://arxiv.org/abs/2104.06615" target="_blank">arXiv</a>]
                </LI>

                <LI style="padding-top:15px;padding-bottom:15px;">
                  <a href="https://arxiv.org/pdf/2106.03128.pdf" target="_blank">
                  <papertitle>MOC-GAN: Mixing Objects and Captions to Generate Realistic Images</papertitle>
                  </a>
                  <br> <strong>T. Ma</strong>, Y. Li
                  <br>
                  <em>arXiv preprint</em>, 2020
                  <br>
                  [<a href="https://arxiv.org/abs/2106.03128" target="_blank">arXiv</a>]
                </LI>
              </ul>
            </td>
          </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;padding-top:5px;vertical-align:middle;">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>Academic Activities</heading>
                </p>
                <p>
                  <LI> Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ACM MM, AAAI.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;">
                <p style="width:90%;border-bottom:1.5px solid;border-bottom-color:#D3D3D3;">
                  <heading>Teaching</heading>
                </p>
                <p>
                  <LI> [2023.02 - 2023.05] TA of ENGG4512 Digitial Image Processing.
                  <LI> [2022.10 - 2022.12] TA of ENGG2310B Communication Systems.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

      </td>
    </tr>
  </table>

<!--   <table width="45%" align="center" border="0" cellspacing="0" cellpadding="10">
    <tbody><tr>
      <td>
        <br>
        <p align="right"><font size="3" color="#A3A3A3">
          Last updated: 09/26/2024
        </font>
        </p>
      </td>
    </tr>
    </tbody>
  </table> -->
  
  <div style="width:25%;height:200px;margin:0 auto;margin-top:30px;"><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=t0fhaZ1HLopKisRzWR8QUFKHvIue8_fF8BR7YYgH6Os'></script></div>
  
  <table width="40%" align="center" border="0" cellspacing="0" cellpadding="0">
    <tbody>
      <tr>
      <td>
        <p align="center">
          <font size="3">
            &copy Tao Ma &nbsp; | &nbsp;
          </font>
          <font size="3">
            Last updated: 2024-12-13 &nbsp; | &nbsp;
          </font>
          <font size="1">
            <a href="http://jonbarron.info/">Website Template</a>
          </font>
        </p>
      </td>
      </tr>
    </tbody>
  </table>

</body>
</html>
